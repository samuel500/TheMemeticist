---
layout: post
title:  "Patrick Collison on Effective Altruism"
date:   2020-06-23 09:37:43 +0000
author: Samuel Knoche
categories: education
comments: true
---

*[Crossposted](https://forum.effectivealtruism.org/posts/xBBXf7KXZCKHYBxeZ/patrick-collison-on-effective-altruism) on the EA Forum.*

Effective Altruism came up in a recent [discussion between Patrick Collison and Jason Crawford](https://youtu.be/8rxS6kj5Zt0?t=1785) on the topic of [Progress Studies](https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/). This is a transcript of the relevant passage. Edited for clarity.

**Jason Crawford:** So compare and contrast the effective altruism movement with progress studies, and I would love to hear you comment on the notion of existential risk or global catastrophic risk.

**Patrick Collison:** On EA... Well… with anything that’s a kind of a totalizing framework and I don't mean that pejoratively, I just mean that in principle everyone could have an EA mindset and I'm sure at least some EA members think that everyone should have an EA oriented mindset. And so you can then sort of ask the question of well, would it be good for everyone to have an EA mindset? But of course the other way of asking it is, is EA on the current margin a good new way for people to be thinking and would it be good, if instead of zero people before the EA movement to be thinking in an EA oriented fashion, would it be good for 5% of people or for 10% of people to be thinking that way? And in the latter sense, was it a good shift on the margin? I think EA has been great and I'm sort-of delighted that they have had the progress they they've had.

Now if the question is, should everyone be an EA or even, I guess in the individual sense, am I or do I think I should be an EA? I think – and obviously there's kind of heterogeneity within the field – but my general sense is that the EA movement is always very focused on kind of rigid, not rigid, that's that's unfair perhaps, but on sort of, estimation, analytical, quantification, and sort of utilitarian calculation, and I think that that as a practical matter that means that you end up too focused on that which you can measure, which again means – or as a practical matter means – you're too focus on things that are sort of short-term like bed nets or deworming or whatever being obvious examples. And are those good causes? I would say almost definitely yes, obviously. Now we've seen some new data over the last couple of years that maybe they’re not as good as they initially seemed but they're very likely to be really good things to do.

But it's hard for me to see how, you know, writing a treatise of human nature would score really highly in an EA oriented framework. As assessed ex-post that looked like a really valuable thing for Hume to do. And similarly, as we have a look at the things that in hindsight seem like very good things to have happen in the world, it's often unclear to me how an EA oriented intuition might have caused somebody to do so. And so I guess I think of EA as sort of like a metal detector, and they've invented a new kind of metal detector that's really good at detecting some metals that other detectors are not very good at detecting. But I actually think we need some diversity in the different metallic substances which our detectors are attuned to, and for me EA would not be the only one.

**Jason Crawford:** Good metaphor. And what about the particular concerns about global catastrophic risk or existential risks especially from technology. This is where I get sort of the most, I won't even say push back exactly, but concern from people about progress studies, is the question of, if we just run full throttle with progress what about the risk of, we're just not careful enough and we get some catastrophe.

**Patrick Collison:** Yeah, I think it is probably true that the optimal rate of technological change is not monotonically better the more that there is. There probably are kind of shear forces with society at a certain point. I think the question is to, as a practical matter should our concern be having too much or having too little. And actually, I should say I don't want to conflate ‘progress’ in progress studies with purely technological advancement, but it’s still a significant part of it. And generally I think, looking historically I think that too little has been a problem far more frequently than too much. I think that today in many super obvious ways we have... too many lives are not as good as they obviously could be, and so in a very tangible sense we have too little progress, and I think there are very valid ways in which one could imagine having too much.

But I guess, I feel sort of, for every one unit of concern I give to ‘too much’ I give it four or five to ‘we have too little.’ Now there is an asymmetry there where the existential risks are, by definition, existential and I thought Toby Ord’s book was a great contribution. Broadly I think the existential risks folks, again, have introduced a good line of thinking that we really should be taking seriously. I suspect that it's possible to mitigate most of those risks relatively effectively without redirecting vast swathes of society and I think the more difficult problem will actually be how do we generate enough.

